#!/usr/bin/env python3
#
# Copyright (c) 2024 Antti Kervinen <antti.kervinen@gmail.com>
#
# License (MIT):
#
# Permission is hereby granted, free of charge, to any person
# obtaining a copy of this software and associated documentation files
# (the "Software"), to deal in the Software without restriction,
# including without limitation the rights to use, copy, modify, merge,
# publish, distribute, sublicense, and/or sell copies of the Software,
# and to permit persons to whom the Software is furnished to do so,
# subject to the following conditions:
#
# The above copyright notice and this permission notice shall be
# included in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
# BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
# ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

r"""csv-query [options] FILE...

Options:
  -h, --help
  -c, --columns                      output only column headers (field names)
  -C, --no-columns                   do not output column headers at all
  -d, --delimiter DELIMITER          set field separator, the default is ";"
  -D, --out-delimiter OUT_DELIMITER  set output field separator, the default
                                     is DELIMITER.
  -W, --out-width COLWIDTH           set output column width.
  -t, --type TYPE                    convert input field values into TYPE
                                     ("f" for float, "i" for integer)
                                     where possible. Avoids conversions in
                                     EXPRs.

Options for SQL-like queries:
  -s, --select FIELDSPEC[<DELIMITER> FIELDSPEC...] output values from selected
                                     fields.
                                     FIELDSPEC ::= FIELD | [NAME] "=" EXPR
                                     FIELDs can contain wildcards.
                                     NAME is column name for EXPR value.
                                     If NAME is omitted, EXPR is used as NAME.
                                     The default is --select "*".
  -w, --where EXPR                   output only rows where EXPR is True.
  -g, --group [[NAME]=]EXPR          Group rows by the value of EXPR. Every
                                     separate value forms a new group of data.
                                     If NAME is given, value of EXPR will be
                                     included in output in column NAME. If only
                                     = is given without name, EXPR is the column.
Scalar functions in EXPR:
  i(field), f(field), s(field)       field value as integer, float or string.

Aggregate functions in EXPR in --select
  I(field), F(field), S(field)       field as int, float and string array.
  SUM(field), COUNT(field)           sum and number of elements in field.
  AVG(field), SD(field), VAR(field)  average, standard deviation and variance.
  COV(f0, f1), CORR(f0, f1)          covariance and correlation of two fields.
  PCT(n, field), MIN(field), MAX(field)  the nth percentile, min and max.
  SORTED(field)                      field values sorted
  STRJOIN(delim, field)              join string fields with delim.
  UNIQ(field)                        unique values in field

Examples:
  csv-query -f my-cats.csv \
    -s name -s age \
    -w "i(age)>=4 and f(weight)>4.5 and name.startswith('Marshmal')"

  csv-query --type float -f my-cats.csv \
    -s 'avg_weight=AVG(weight);name' -g 'age//5'
"""

import csv
import fnmatch
import getopt
import re
import statistics
import sys

# error prints error message and exits process
def error(msg, exit_status=1):
    if msg:
        sys.stderr.write("csv-query: %s\n" % (msg,))
    if exit_status is not None:
        sys.exit(exit_status)

def query(data, fields, filt, group):
    if len(data) == 0:
        return []
    data_fields = set(data[0].keys())
    result = []
    aggr_funcs = {
        "F": lambda v: [float(f) for f in v],
        "I": lambda v: [int(i) for i in v],
        "S": lambda v: [str(s) for s in v],
        "AVG": lambda v: sum(v)/len(v) if len(v)>0 else "nan",
        "SUM": lambda v: sum(v),
        "COUNT": lambda v: len(v),
        "PCT": lambda n, v: sorted(v)[int(len(v)*n/100) if n<100 else -1] if len(v)>0 else "nan",
        "MIN": lambda v: min(v) if len(v)>0 else "nan",
        "MAX": lambda v: max(v) if len(v)>0 else "nan",
        "VAR": lambda v: statistics.variance(v) if len(v)>1 else "nan",
        "SD": lambda v: statistics.stdev(v) if len(v)>1 else "nan",
        "COV": lambda v0, v1: statistics.covariance(v0, v1) if len(v0)>1 else "nan",
        "CORR": lambda v0, v1: statistics.correlation(v0, v1) if len(v0)>1 else "nan",
        "ROUND": lambda v: [round(e) for e in v],
        "SORTED": lambda v: sorted(v),
        "STRJOIN": lambda delim, v: delim.join([str(e) for e in v]),
        "UNIQ": lambda v: sorted(set(v)),
    }
    aggr_func_names = set(aggr_funcs.keys())
    scalar_funcs = {
        "f": lambda v: float(v),
        "i": lambda v: int(v),
        "s": lambda v: str(v),
    }
    typeid_castf = dict(aggr_funcs)
    typeid_castf.update(scalar_funcs)
    typed_data_init = {key:{} for key in typeid_castf}
    filtered_data = []
    groupid_resultindex = {}

    field_exprs = []
    field_funcs = []
    field_names = []
    field_idx = []
    field_aggr = []
    extra_fields = []

    for i, field in enumerate(fields):
        if isinstance(field, tuple): # field is (name, expr)
            ff = eval("lambda:" + field[1])
            field_exprs.append(field[1])
            field_funcs.append(ff)
            field_names.append(field[0])
            field_idx.append(i)
            field_aggr.append(len(set(ff.__code__.co_names).intersection(aggr_func_names)) > 0)
            fields[i] = field[0] # replace (name, expr) with name only
    group_id_field = None
    if sum(field_aggr) > 0 and group is None:
        # there are aggregate functions but no grouping => put all to the same group
        group = ("", "0")

    if group:
        group_id_field = group[0] if group[0] else "groupid"

    if group is not None:
        field_exprs.append(group[1])
        field_funcs.append(eval("lambda:" + group[1]))
        field_names.append(group_id_field)
        field_idx.append(len(fields))
        field_aggr.append(False)
    extra_fields = sorted(
        set([n
             for ff in field_funcs
             for n in ff.__code__.co_names
             if n in data_fields and n not in fields
             ]))
    if group is not None:
        if group_id_field != "groupid":
            fields.append(group_id_field)
        else:
            extra_fields.append(group_id_field)

    filtered_data = []
    env = dict(typeid_castf)
    for row in data:
        env['row'] = row
        env.update(row)
        for i, ff in enumerate(field_funcs):
            if field_aggr[i]: # aggregate functions will be evaluated after grouping
                continue
            field_value = eval(ff.__code__, env)
            env[field_names[i]] = field_value
            row[field_names[i]] = field_value
        if filt is None or eval(filt.__code__, env):
            filtered_data.append(row)

    user_and_extra_fields = fields + extra_fields
    for row in filtered_data:
        if group is None:
            result.append([row[field] for field in fields])
        else:
            group_value = row[group_id_field]
            resultindex = groupid_resultindex.get(group_value, None)
            if resultindex is None:
                resultindex = len(result)
                groupid_resultindex[group_value] = resultindex
                result.append([[] for _ in range(len(user_and_extra_fields))])
            for fieldindex, field in enumerate(user_and_extra_fields):
                if field == group_id_field:
                    result[resultindex][fieldindex] = row[field]
                elif field in row: # named aggregate fields are not yet in row
                    result[resultindex][fieldindex].append(row[field])

    if group is not None:
        aggregated_result = []
        env = dict(typeid_castf)
        for resrow in result:
            aggregated_result.append([resrow[i] for i in range(len(fields))])
            env.update({field: resrow[i] for i, field in enumerate(user_and_extra_fields)})
            try:
                for i, ff in enumerate(field_funcs):
                    if field_idx[i] < len(fields):
                        if field_aggr[i]:
                            aggregated_result[-1][field_idx[i]] = eval(ff.__code__, env)
            except Exception as e:
                error("group aggregation error on field %s, code %s: %s" %
                      (field_names[i], field_exprs[i], e))
            result = aggregated_result

    return result

if __name__ == "__main__":
    import getopt
    opt_columns = False
    opt_no_columns = False
    opt_files = []
    opt_delimiter = ";"
    opt_out_delimiter = None
    opt_out_width = None
    opt_select = []
    opt_where = None
    opt_group = None
    opt_type = None
    try:
        opts, remainder = getopt.gnu_getopt(
            sys.argv[1:], 'hcCd:D:W:f:s:w:g:t:',
            ['help', 'columns', 'no-columns', 'delimiter=', 'out-delimiter=',
             'out-width=', 'type=',
             'file=', 'select=', 'where=', 'group='])
    except Exception as e:
        error(str(e))
    for opt, arg in opts:
        if opt in ["-h", "--help"]:
            print(__doc__)
            sys.exit(0)
        elif opt in ["-c", "--columns"]:
            opt_columns = True
        elif opt in ["-C", "--no-columns"]:
            opt_no_columns = True
        elif opt in ["-f", "--file"]:
            opt_files.append(arg)
        elif opt in ["-d", "--delimiter"]:
            opt_delimiter = arg
        elif opt in ["-D", "--out-delimiter"]:
            opt_out_delimiter = arg
        elif opt in ["-W", "--out-width"]:
            opt_out_width = int(arg)
        elif opt in ["-s", "--select"]:
            opt_select.extend(arg.split(opt_delimiter))
        elif opt in ["-w", "--where"]:
            if opt_where is not None:
                error("multiple -w/--where expressions")
            opt_where = eval("lambda:" + arg)
        elif opt in ["-g", "--group"]:
            if opt_group is not None:
                error("multiple -g/--group expressions")
            m = re.match('([a-zA-Z0-9_]*)=(?!=)(.*)', arg)
            if m:
                field, expr = m.groups()
                if field == "":
                    field = expr
            else:
                field, expr = "", arg
            opt_group = (field, expr)
        elif opt in ["-t", "--type"]:
            try:
                opt_type = {"f": float, "float": float,
                            "i": int, "int": int}[arg.lower()]
            except KeyError:
                error("invalid -t/--type '%s', expected 'f', 'i'" % (arg,))
        else:
            error("internal error: unhandled option '%s'" % (opt,))

    if opt_out_delimiter is None:
        opt_out_delimiter = opt_delimiter

    opt_files.extend(remainder)
    if len(opt_files) == 0:
        opt_files.append("-")

    if opt_where is not None and len(opt_select) == 0:
        opt_select.append("*")
    if opt_where is None and opt_group is not None:
        opt_where = lambda: True

    for fname in opt_files:
        if fname == "-":
            data_reader = csv.DictReader(sys.stdin, delimiter=opt_delimiter)
        else:
            data_reader = csv.DictReader(open(fname), delimiter=opt_delimiter)
        if opt_columns:
            print(opt_delimiter.join(col for col in data_reader.fieldnames))
        if opt_select:
            data = [row for row in data_reader]
            if opt_type:
                for row in data:
                    for field in row:
                        try:
                            row[field] = opt_type(row[field])
                        except ValueError:
                            pass
            fields = []
            for field_pattern in opt_select:
                m = re.match('([a-zA-Z0-9_]*)=(?!=)(.*)', field_pattern)
                if m: # expression field
                    field, expr = m.groups()
                    if field == "":
                        field = expr
                    fields.append((field, expr))
                else:
                    fields.extend([f for f in data_reader.fieldnames if fnmatch.fnmatch(f, field_pattern)])
            result = query(data, fields, opt_where, opt_group)
            try:
                if opt_out_width is not None:
                    fmt = "%" + str(opt_out_width) + "s"
                    fields = [fmt % (s,) for s in fields]
                    for row_idx, row in enumerate(result):
                        result[row_idx] = [fmt % (col,) for col in row]
                if not opt_no_columns:
                    print(opt_out_delimiter.join(fields))
                for row in result:
                    print(opt_out_delimiter.join([str(col) for col in row]))
            except:
                error("", 0)
